# OpenGLES-Preemptive-contexts
## OpenGL的渲染管线并行 / 异步机制的工作原理
GPU是一个并行处理器，擅长同时处理大量的相同任务。举个可能不太合适的例子，

- 课堂上老师需要把改完的试卷发给每一位学生，这个事情如果放在单核的CPU上去处理，那么老师得挨个把试卷交给每个学生手上，50个学生的话他就得处理50次。本质上发试卷是对同一任务的一个50次重复，唯一不同的是需要处理的数据不一样（即试卷）。当然老师也可以找课代表或者组长来协助，这也就相当于多核CPU，每人承担一部分工作。
- 发试卷这个任务本身是没有前后顺序依赖的，给张三先发还是给李四先发，并没有任何区别，说明这是个可以并发的任务。GPU就是设计来处理类似任务的，如果把GPU比作老师的话，那么这位老师就仿佛如孙猴子拔了一撮猴毛，幻化出n个分身，每个分身都可以单独去处理发试卷的任务，从而实现了并发。

在计算机图形图像处理中，不管是处理顶点、像素或者图元，这类任务都跟发试卷一样，具备了高度可并发的特点。就拿顶点举个例子，假如有一个兔子网格模型，上面有10000个顶点，那么当这个兔子模型发生旋转的时候，这10000个顶点每个都参与了相同的运算，即乘了一个旋转矩阵。这10000个顶点的旋转运算彼此没有任何顺序上的依赖，是完全可以并行处理的。

另一方面，GPU在处理并行计算时，和CPU的请求之间通常是异步的。具体表现在OpenGL上，CPU是客户端，GPU是服务端，他们之间是一个C/S的架构设计。在CPU发起GL调用时，为了得到最好的性能，驱动会尝试尽快地把调用指令发送给GPU，但GPU对这些指令的响应不是实时的，更不是同步的。这些指令只是添加到了GPU的指令队列里，CPU发出请求后马上返回了，几乎不耗时，而GPU则根据自己的能力挨个去处理，是一个生产者/消费者模式。如果GPU收到的指令过于密集，那么指令队列可能就满了，这会导致驱动需要把这些指令保存在Context的调用缓存里（即指令都堆积在了客户端线程的缓存里）。

OpenGL的异步命令解放了CPU，使得CPU可以不必傻傻等待GPU处理完，但是CPU如果想知道GPU目前处理到了什么程度，想掌握GPU的工作进展的话，就不好办了。那么CPU和GPU是怎么同步的呢？

## 实现CPU和GPU的同步
这里有两种方法供使用
1. glFlush, glFinish和eglSwapBuffers

在调用glFlush后，该操作将会阻塞当前线程，直到所有Context缓存中的指令指令都发送给了GPU后才继续执行。glFinish这个命令更加强大，它会阻塞当前线程，直到所有的指令都发送给了GPU并执行完毕后才继续执行。显然glFinish在渲染线程里比glFlush更容易产生阻塞，应用程序的性能会因此下降。eglSwapBuffers相当于隐式调用了glFinish。

2. 使用Fence

OpenGL ES 3.0后开始支持同步对象和栅栏，可以实现CPU和GPU的同步。

## 抢占式上下文
顾名思义，抢占式上下文是不同优先级的上下文对GPU资源的抢占。为什么需要抢占呢？一个典型的用例是在ARVR设备ATW方案的实现。在ATW中，存在两种完全不同的渲染
- 常规帧渲染
- ATW帧渲染

在常规帧渲染时，GPU有条不紊地按照自己的节奏工作，但这些只渲染到FBO上。而ATW帧渲染是对常规帧渲染结果进行重投影后的二次渲染，这个渲染是上屏渲染。为了降低M2P延迟，ATW帧渲染需要能在一个vsync周期内完成，这就要求该线程具有更高的渲染优先级。

# Sample code
有了上面这些知识的铺垫，我们不妨写一个简单的Demo来体验一下Android上CPU和GPU的同步，以及不同优先级渲染上下文对应的线程上，对GPU资源的抢占。
